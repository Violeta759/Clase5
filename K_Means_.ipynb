{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "w5_DgsZQdRun",
        "X5cPeZvTahiZ",
        "JHbcmhyUazeI",
        "bJ11B2i9zQld",
        "1yVXxQkwq0jg",
        "QoA6sfCK-Q1C",
        "T7ioThU_xslx",
        "OAPHJat_zlop",
        "sIdGS_elOgQW"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Violeta759/Sesi-n5/blob/main/K_Means_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkOHP68hTuRZ"
      },
      "source": [
        "# K-Means\n",
        "\n",
        "***Objetivo:***\n",
        "\n",
        "Dado un conjunto $X=\\{e_1,\\dots,e_m \\}$.\n",
        "\n",
        "Encontrar una K-partición o conjunto de centroides $Centroides=\\{ \\mu_1,\\ldots,\\mu_k \\}$. \n",
        "\n",
        "Tal que hace mínimo $\\sum^m_{i=0}min_{\\mu_j \\in Centroides} (|| e_i -\\mu_j||^2)$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ai2nA60-WWfA"
      },
      "source": [
        "# Algoritmo Paso a Paso."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Librería y datos:"
      ],
      "metadata": {
        "id": "w5_DgsZQdRun"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOKQoUzV4KvB"
      },
      "source": [
        "#Cargando librerías. \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt #Librería de gráficos etc. -> matplotlib\n",
        "from sklearn.datasets import make_blobs # T= Sólo importa make_blobs de sklearn.\n",
        "import random "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LweA5M2Y-p_J"
      },
      "source": [
        "plt.figure(figsize=(12, 12))\n",
        "#Tamaño de tela donde quiero pintar. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxNuYecnWe9P"
      },
      "source": [
        "Generamos datos 1500 sintéticos con 3 distribuciones gausianas aleatorias y los mostramos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTmlymgc5BTn"
      },
      "source": [
        "random_state = 170 #Semilla. \n",
        "n_samples = 1500\n",
        "\n",
        "x, y = make_blobs(n_samples=n_samples, random_state=random_state)\n",
        "# T = random_state=random_state -> para tener todos lo mismo. \n",
        "X=pd.DataFrame(x)\n",
        "# x: son los valores,y: clase a la que pertenecen. \n",
        "\n",
        "plt.scatter(X.loc[:, 0], X.loc[:, 1], c=y)\n",
        "# X.loc[:, 0] -> .loc es para decirle que parte de las columnas del data frame quiero. En este caso las columnas se llaman 0 y 1. \n",
        "# c=y me lo colorea por categorías. \n",
        "plt.title(\"Datos Iniciales\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5cPeZvTahiZ"
      },
      "source": [
        "## Inicialización:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9lWnZn7W9YP"
      },
      "source": [
        "Generamos los primeros **Centroides** aleatorios."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b41vb-JU6kJG"
      },
      "source": [
        "K=3\n",
        "Centroides=np.random.random((K,2))*20.0-10.0 \n",
        "#El primer radom es el nombre de la librería y el segundo es el comando. \n",
        "plt.scatter(X.loc[:, 0], X.loc[:, 1])\n",
        "plt.scatter(Centroides[:,0], Centroides[:,1], marker='x',c=[0,1,2])\n",
        "plt.title(\"Primeros Centroides\")\n",
        "print(Centroides)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-9rDaIvX5Fk"
      },
      "source": [
        "Definimos la métrica $||x-\\mu||^2$ entre el centroide y los puntos para seleccionar el centroide más cercano para cada punto\n",
        "como la **distancia euclídea** entre el punto en dos dimensiones $x=(x_0,x_1)$ y el centroide $\\mu=(\\mu_0.\\mu_1)$.\n",
        "\n",
        "$d(x,\\mu)=\\sqrt{(x_0 - \\mu_0)^2+(x_1 - \\mu_1)^2}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1ytVppwApoO"
      },
      "source": [
        "def distancia(X1,C): \n",
        "  #Le damos un punto y una correción de centroides. C es el vector de Centroides y X1 es el punto.\n",
        "  # Construimos el vector de distancias del punto a cada centroide.\n",
        "  arr=[(sum((X1 - c)**2))**0.5 for c in C]\n",
        "  #Obtengo la distancia de cada punto a cada uno de los centroides. \n",
        "  #Seleccionamos el índice (identificador del centroide) de mínimma distancia y los devolvemos.\n",
        "  return np.where(arr == np.amin(arr))[0][0] #Con esta línea le digo que me coja el centroide con menor distancia a ese punto. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Opcrl-PHZ-On"
      },
      "source": [
        "Para todos los puntos calculamos cual es su centoide más cercano."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOnk-eJOAWoH"
      },
      "source": [
        "X['C']=X.iloc[:,:-1].apply(distancia,axis=1,C=Centroides)\n",
        "#Aplico a cada fila la función distancia que la acabo de definir. Metemos los parámetros de la función distancia: el parámetro y el C. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfRwaVvKcOop"
      },
      "source": [
        "X['C'].hist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tengo menos centroides realmente. Recalculo."
      ],
      "metadata": {
        "id": "x0k1K-TjVDJW"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHbcmhyUazeI"
      },
      "source": [
        "## Recálculo de los nuevos centroides:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A. Reaguste de los datos con los nuevos centroides.**"
      ],
      "metadata": {
        "id": "0PyGeFndgUqh"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHt4UDg5XIfg"
      },
      "source": [
        "C=X.groupby(['C']).mean().values\n",
        "if(len(C)<len(Centroides)):\n",
        "  C=np.vstack([C,np.random.random((len(Centroides)-len(C),2))*20.0-10.0])\n",
        "plt.scatter(X.loc[:, 0], X.loc[:, 1],c=X['C'])\n",
        "plt.scatter(C[:,0], C[:,1], marker='x',c=[0,1,2])\n",
        "plt.title(\"Nueva asignación\")\n",
        "print(C)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qB59YQPuaCEp"
      },
      "source": [
        "X['C']=X.iloc[:,:-1].apply(distancia,axis=1,C=C)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxHcCkcBb6TX"
      },
      "source": [
        "**B. Recáculo de los nuevos centroides.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5-UBeCxa1zv"
      },
      "source": [
        "C1=X.groupby(['C']).mean().values\n",
        "if(len(C1)<len(Centroides)):\n",
        "  C1=np.vstack([C1,np.random.random((len(Centroides)-len(C1),2))*20.0-10.0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nRviKQxaWnH"
      },
      "source": [
        "plt.scatter(X.loc[:, 0], X.loc[:, 1],c=X['C'])\n",
        "plt.scatter(C1[:,0], C1[:,1], marker='x',c=[0,1,2])\n",
        "plt.title(\"Nueva asignación\")\n",
        "print(C1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlI06oCvbnd_"
      },
      "source": [
        "diferencia=np.amax(abs(C-C1))\n",
        "print(C)\n",
        "C=C1\n",
        "print(diferencia)\n",
        "print(C)\n",
        "#El valor central (1.4790595521958159) es la diferencia máxima que existe entre los centroides. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltq-0t-zcXzX"
      },
      "source": [
        "Si la diferencia entre los nuevos centrodes C1 y los antíguos no es la adecuada volver a **(A)**."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vas iterando hasta que te salga. Aunque lo suyo es hacer un bucle para agilizar."
      ],
      "metadata": {
        "id": "Z42a3JW2XAZx"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SLDAUk3jbhK"
      },
      "source": [
        "## ***IMPORTANTE***: **Sciki-Learn** [K-Mean](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans). En esta librería va casi todo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJ11B2i9zQld"
      },
      "source": [
        "## Ejemplo 1:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBB31RQKjjyE"
      },
      "source": [
        "# Author: Phil Roth <mr.phil.roth@gmail.com>\n",
        "# License: BSD 3 clause\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.datasets import make_blobs\n",
        "\n",
        "plt.figure(figsize=(12, 12))\n",
        "\n",
        "n_samples = 1500\n",
        "random_state = 170\n",
        "X, y = make_blobs(n_samples=n_samples, random_state=random_state)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGuG_E-2j0fA"
      },
      "source": [
        "KM= KMeans(n_clusters=3, random_state=random_state) #Creamos el modelo. \n",
        "y_pred=KM.fit_predict(X) #Ajusto\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y_pred)\n",
        "plt.title(\"Resultados\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCvybUxlly5k"
      },
      "source": [
        "- **Atributos** del Objeto K-means:\n",
        "\n",
        "|Attributo|Significado|\n",
        "|---------|-----------|\n",
        "|**cluster_centers**| Coordenadas de los centroides|\n",
        "|**labels**|Grupo de cada punto|\n",
        "|**inertia**| Suma de los cuadrados de los puntos de cada grupo a su centroide|\n",
        "|**n_iter**| Número de iteraciones|\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25wMXvqelqTZ"
      },
      "source": [
        "print(KM.cluster_centers_) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## k-means ++ hace una inspección de datos para encontrar una distribución de los datos, y luego encuentra unos centroides lo más separados entre sí."
      ],
      "metadata": {
        "id": "eAW3Nvw2azPZ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yVXxQkwq0jg"
      },
      "source": [
        "## Ejemplo 2: Pasaje del Titatic."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded= files.upload()"
      ],
      "metadata": {
        "id": "bkaSPPncgowZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcEKdzFqrFyh"
      },
      "source": [
        "#%cd /content/drive/My Drive/sesion5/k-means"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yZpAgkKq7Ct"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(12, 12))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ualOqQIsrT6V"
      },
      "source": [
        "Leer los datos del pasaje del fichero titanic.csv mediante **pd.load_csv()**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mU_R9rgbrnVF"
      },
      "source": [
        "titanic=pd.read_csv('titanic.csv')\n",
        "cluster_data = titanic[['Fare','Age']].copy(deep=True)\n",
        "cluster_data.dropna(axis=0, inplace=True)\n",
        "cluster_data.sort_values(by=['Fare','Age'], inplace=True)\n",
        "cluster_array = np.array(cluster_data)\n",
        "print(cluster_data.head())\n",
        "plt.scatter(cluster_array[:,0],cluster_array[:,1]) #Lo pinto.\n",
        "#Selecciona los años y el coste del pasaje. \n",
        "titanic.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> La y son los años y la x el coste. "
      ],
      "metadata": {
        "id": "qrjw0LLgi58z"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hryy_QeNsh3i"
      },
      "source": [
        "KM=KMeans(n_clusters=2)\n",
        "y_pred=KM.fit_predict(cluster_array)\n",
        "plt.scatter(cluster_array[:,0],cluster_array[:,1],c=y_pred)\n",
        "print(KM.cluster_centers_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "No tiene mucho sentido así que normalizamos los datos. Es decir, cambiamos la escala de los mismos a otra escala distinta que sea de interés. "
      ],
      "metadata": {
        "id": "Hf4kmV2EjkQV"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QoA6sfCK-Q1C"
      },
      "source": [
        "### Normalizar los datos:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3hPLLbG-Wsp"
      },
      "source": [
        "Entre los diferentes tipos de normalización de los valores de los datos que podemos hacer, están:\n",
        "\n",
        "- Escalado frente al máximo : $x'=\\frac{x}{máx(|X|)}$.\n",
        "- Normalización entre el mínimo y máximo: $x'=\\frac{x-x_{mín}}{x_{máx}-x_{mín}}$.\n",
        "- Estandarización. Siendo $\\mu_x$, $\\sigma_x$  la media de y desviación estandar de  X: $x_{std}=\\frac{x-\\mu}{\\sigma}$. Sino tenemos conocimiento en qué tenemos que hacer, seleccionamos esta."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11DTfVg1BKpS"
      },
      "source": [
        "#### **Escalado con el máximo**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xmq8xllBRLh"
      },
      "source": [
        "from sklearn.preprocessing import MaxAbsScaler\n",
        "# Creamos el objeto an abs_scaler.\n",
        "abs_scaler = MaxAbsScaler()\n",
        "abs_scaler.fit(cluster_array)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTi4t7WICBFJ"
      },
      "source": [
        "# The maximum absolute values calculated by the fit method.\n",
        "abs_scaler.max_abs_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TVuJbqdCPVR"
      },
      "source": [
        "#Escalamos los datos.\n",
        "scaled_data = abs_scaler.transform(cluster_array) #Hacemos la transformación y lo pintamos. \n",
        "plt.scatter(scaled_data[:,0],scaled_data[:,1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SG2mxBALC3wl"
      },
      "source": [
        "KM=KMeans(n_clusters=2)\n",
        "y_pred=KM.fit_predict(scaled_data)\n",
        "plt.scatter(scaled_data[:,0],scaled_data[:,1],c=y_pred)\n",
        "print(KM.cluster_centers_)\n",
        "#Nos divide por la cosa más relevante que es la edad. Hemos pasado de agrupar por el coste del billete a por la edad, simplemente por el cambio de escala. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyX_D08MDa4x"
      },
      "source": [
        "abs_scaler.inverse_transform(KM.cluster_centers_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zS-WmXfaEBaS"
      },
      "source": [
        "#### **Mínimo-Máximo.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyPUaUdpD3yS"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "# Creamos el objeto an abs_scaler.\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(cluster_array)\n",
        "# Escalamos los datos.\n",
        "scaled_data = abs_scaler.transform(cluster_array)\n",
        "plt.scatter(scaled_data[:,0],scaled_data[:,1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCaeke4TEzI6"
      },
      "source": [
        "KM=KMeans(n_clusters=2)\n",
        "y_pred=KM.fit_predict(scaled_data)\n",
        "plt.scatter(scaled_data[:,0],scaled_data[:,1],c=y_pred)\n",
        "print(KM.cluster_centers_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywqBAKUaE-SB"
      },
      "source": [
        "scaler.inverse_transform(KM.cluster_centers_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sale más o menos igual que la anterior porque va entre 0 y 1. "
      ],
      "metadata": {
        "id": "cWJ-2iQ9lG6a"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8F6y3gmFGxzC"
      },
      "source": [
        "#### **Estandarizar.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8laxAEYG2Vp"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "# Creamos el objeto an abs_scaler.\n",
        "standar = StandardScaler()\n",
        "standar.fit(cluster_array)\n",
        "# Escalamos los datos.\n",
        "scaled_data = standar.transform(cluster_array)\n",
        "plt.scatter(scaled_data[:,0],scaled_data[:,1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La media está puesta en el 0,0."
      ],
      "metadata": {
        "id": "Pw9hk0FHlNpN"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tT541VXHUoV"
      },
      "source": [
        "KM=KMeans(n_clusters=2)\n",
        "y_pred=KM.fit_predict(scaled_data)\n",
        "plt.scatter(scaled_data[:,0],scaled_data[:,1],c=y_pred)\n",
        "print(KM.cluster_centers_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este es el mejor, ya que incorpora ambos ejes (el de edad y el del coste)."
      ],
      "metadata": {
        "id": "RY75dFHGlYB8"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIkztn9rHgzh"
      },
      "source": [
        "scaler.inverse_transform(KM.cluster_centers_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7ioThU_xslx"
      },
      "source": [
        "## Ejemplo 3: Flores Iris."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TunHJKn0xzN9"
      },
      "source": [
        "from sklearn import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "X, y = datasets.load_iris(return_X_y=True)\n",
        "#X: ndarray, y: tipo de florecitas. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMyp1ZuvyFWQ"
      },
      "source": [
        "KM = KMeans(n_clusters=3, random_state=1).fit(X)\n",
        "# Ahora ponemos esto .fit(X) porque al resultado le aplico el ajuste directamente. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrY1IjMTyXCQ"
      },
      "source": [
        "KM.cluster_centers_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kyV1ikgy2LA"
      },
      "source": [
        "KM.inertia_ #valor de inercia= valor medio de compacidad de los elementos. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAPHJat_zlop"
      },
      "source": [
        "# Calidad de la partición (cuántas clases):\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**AHORA NOS PLANTEAMOS CUÁNTAS CLASES HACEMOS:**\n",
        "\n",
        " Coeficiente [**Silhouette**](https://scikit-learn.org/stable/modules/clustering.html#clustering-performance-evaluation).\n",
        "\n",
        "EL coefiente de  **Silhouette** (SIMILUTUD DE LOS ELEMENTOS DE LA CLASE X CON RESPECTO A LAS OTRAS CLASES) está definido para cada ejemplo y consta de dos mediadas:\n",
        "\n",
        "- **a:** La media de la distancia entre un punto y **todos los puntos de su grupo**. Lo que me parezco a los míos. \n",
        "- **b:** La media de la distancia entre un punto y **todos los puntos de su grupo más cercano** distinto al suyo. \n",
        "\n",
        "El coeficiente para un punto simple se calcula como: $s=\\frac{b-a}{máx(a,b)}$.\n",
        "\n",
        "**La difencia entre a y b mejor!!!!**\n",
        "\n",
        "El coeficiente global se calcula como la media de los coeficientes de cada punto.\n",
        "\n",
        "**Cuanto mayor es el valor del coefiente mejor es la agrupación.**"
      ],
      "metadata": {
        "id": "QnZ2458OqJjq"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvjcPqOJ1200"
      },
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.metrics import pairwise_distances\n",
        "from sklearn import datasets\n",
        "X, y = datasets.load_iris(return_X_y=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SefPQnjX2SPh"
      },
      "source": [
        "Un uso normal del coeficiente de **Silhouette**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfcoSUQl2aom"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "kmeans_model = KMeans(n_clusters=3, random_state=1).fit(X)\n",
        "labels = kmeans_model.labels_\n",
        "metrics.silhouette_score(X, labels, metric='euclidean')\n",
        "#0.5528190123564095 valor de Silhoutte para esta partición. Puedo hacer un cluster superior y ver si esta media sube o baja. \n",
        "#La inercia va aumentando con los clusters ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbnUb9NMMK66"
      },
      "source": [
        "## Visualización."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLrd9FXmKILq"
      },
      "source": [
        "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data'\n",
        "cols =  ['Class', 'Alcohol', 'MalicAcid', 'Ash', 'AlcalinityOfAsh', 'Magnesium', 'TotalPhenols', \n",
        "         'Flavanoids', 'NonflavanoidPhenols', 'Proanthocyanins', 'ColorIntensity', \n",
        "         'Hue', 'OD280/OD315', 'Proline']\n",
        "data = pd.read_csv(url, names=cols)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wamJfI-IK8QR"
      },
      "source": [
        "y=data['Class']\n",
        "X=data.loc[:,'Alcohol':]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJn4Z8ltMWZC"
      },
      "source": [
        "### Por piezas en dos dimensiones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEyI0ac4KScZ"
      },
      "source": [
        "# Three different scatter series so the class labels in the legend are distinct-\n",
        "plt.scatter(X[y==1]['Flavanoids'], X[y==1]['NonflavanoidPhenols'], label='Class 1', c='red')\n",
        "plt.scatter(X[y==2]['Flavanoids'], X[y==2]['NonflavanoidPhenols'], label='Class 2', c='blue')\n",
        "plt.scatter(X[y==3]['Flavanoids'], X[y==3]['NonflavanoidPhenols'], label='Class 3', c='lightgreen')\n",
        "\n",
        "# Prettify the graph.\n",
        "plt.legend()\n",
        "plt.xlabel('Flavanoids')\n",
        "plt.ylabel('NonflavanoidPhenols')\n",
        "\n",
        "# Display.\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIdGS_elOgQW"
      },
      "source": [
        "# Reducción de la dimensionalidad:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoXcVW6qPjbR"
      },
      "source": [
        "### Algoritmo **PCA** (**componentes principales**)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foGrBRI5Mll3"
      },
      "source": [
        "from sklearn.decomposition import PCA as sklearnPCA #Hago una descomposición, la que yo quiera. \n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "# Creamos el objeto an abs_scaler.\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(X)\n",
        "X_norm=scaler.transform(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XG1ttW_HN546"
      },
      "source": [
        "pca= sklearnPCA(n_components=2) #2-dimensional LDA.\n",
        "transformed= pd.DataFrame(pca.fit_transform(X_norm, y))\n",
        "plt.scatter(transformed[y==1][0], transformed[y==1][1], label='Class 1', c='red')\n",
        "plt.scatter(transformed[y==2][0], transformed[y==2][1], label='Class 2', c='blue')\n",
        "plt.scatter(transformed[y==3][0], transformed[y==3][1], label='Class 3', c='lightgreen')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()\n",
        "#El clustering no se ha modificado sólo lo hemos representado de forma diferente. Aquí se ve mucho mejor. \n",
        "#Este cluster lo ha hecho cogiendo una componente principal a partir de lo anterior, pero realmente no tiene sentido explicar el gráfico. Sólo me sirve para \n",
        "#ver si he hecho el cluster bien. Si hay grupos claramente definidos, lo he hecho bien. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNZ8m6JLPYCD"
      },
      "source": [
        "### Algoritmo **LDA**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOFLKS8dPx4v"
      },
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "# Creamos el objeto an abs_scaler.\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(X)\n",
        "X_norm=scaler.transform(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjrEWtphQXfj"
      },
      "source": [
        "lda = LDA(n_components=2) #2-dimensional LDA.\n",
        "lda_transformed = pd.DataFrame(lda.fit_transform(X_norm, y))\n",
        "\n",
        "# Plot all three series.\n",
        "plt.scatter(lda_transformed[y==1][0], lda_transformed[y==1][1], label='Class 1', c='red')\n",
        "plt.scatter(lda_transformed[y==2][0], lda_transformed[y==2][1], label='Class 2', c='blue')\n",
        "plt.scatter(lda_transformed[y==3][0], lda_transformed[y==3][1], label='Class 3', c='lightgreen')\n",
        "\n",
        "# Display legend and show plot.\n",
        "plt.legend(loc=3)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}