{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Violeta759/Clase5/blob/main/Tree_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con **JUPITER** puedes editar los colabs y presentar too."
      ],
      "metadata": {
        "id": "OTpMQNWAtR5D"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHoFZ5shYLhl"
      },
      "source": [
        "# Árboles de decisión.\n",
        "Algortimos supervisados (datos y clase).\n",
        "\n",
        "Sea una colección de datos $x_i \\in R^n$ para $i=0,\\ldots,l$ y un vector de etiquetas $y \\in R^l$.\n",
        "\n",
        "Consideremos $Q$ los datos del nodo $m$ y el citerio de partición $\\theta=(j,t_m)$ sobre la característica $j$ y el valor de corte $t_m$ que divide el nodo $Q$ en los dos subconjuntos:\n",
        "\n",
        "- $Q_{izquierda}(\\theta)$ definido como $\\{x \\in Q / x_j \\le t_m\\}$. \n",
        "- $Q_{derecha}(\\theta)$ definido como $\\{x \\in Q / x_j > t_m\\}$.\n",
        "\n",
        "La valoración de criterio  $\\theta$ en el nodo $Q$ se calcula como:\n",
        "- $G(Q,\\theta)=\\frac{n_{izquierdo}}{Q} H(Q_{izquierdo})+ \\frac{n_{derecho}}{Q} H(Q_{derecho})$.\n",
        "\n",
        "Se selecciona el parámtero $\\theta^*$ pare que $G(\\theta^*,Q)$ sea mínimo.\n",
        "\n",
        "De forma recursiva se vuelve a subdivir $Q_{izquierdo}$ y $Q_{derecho}$ hasta alcanzar unos conjuntos unitarios o el criterio para subdividir no se cumpla."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnBBBeIXgv01"
      },
      "source": [
        "# Clasificación $H(Q)$:\n",
        "Evaluación de la uniformidad de un nodo.\n",
        "\n",
        "Consideramos la probabilidad de la clase k en el nodo $Q_m$ es $p_{m,k}=\\frac{1}{N_m} \\sum_{x_i \\in Q_m} I(y_i=k)$.\n",
        "\n",
        "\n",
        "|**Criterio**       |   **Valor**                                              |\n",
        "|-------------------|----------------------------------------------------------|\n",
        "|**Gini**           |$H(Q_m)=\\sum_k p_{m,k}(1-p_{m,k})$                        |\n",
        "|-------------------|----------------------------------------------------------|\n",
        "|**Entropía**       |$H(Q_m)=-\\sum_k p_{m,k}log(p_{m,k})$                      |\n",
        "|-------------------|----------------------------------------------------------|\n",
        "|**Mal clasificación**|$H(Q_m)=1-max(p_{m,k})$                                 |\n",
        "|-------------------|----------------------------------------------------------|\n",
        "\n",
        "- Gini: mide como confluye el acierto y el error. Me da valores altos cuando la clase no es tan clara. El valor máximo es cuando uno de ellos vale 0 porque el valor resultante es 1. Mi objetivo es obtener un valor de gini pequeño.\n",
        "- Entropía: desorden. Probabilidad de encontrarlo. Cuánto más probabilidades sean 0, más cercano a 1. \n",
        "- Mal clasificación: la inversa del máx de la clase que mejor clasifica.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKw6XXibn82E"
      },
      "source": [
        "# Ejemplo de divisiones $\\theta$:\n",
        "Datos de flores Iris."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDzpheUXotex"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "#leemos los datos\n",
        "iris = load_iris()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oT_FDlgncmhU"
      },
      "source": [
        "Creamos el DataFrame  **datos** correspondientes a partir de la librería **sklearn**\n",
        "\n",
        "|                 | Características|                 |                |       |\n",
        "|-----------------|----------------|-----------------|----------------|-------|\n",
        "|sepal length (cm)|sepal width (cm)|petal length (cm)|petal width (cm)| tipos |\n",
        "\n",
        "\n",
        "\n",
        "|Tipos|Clase      |\n",
        "|-----|-----------|\n",
        "0    |setosa\n",
        "1    |versicolor\n",
        "2    |virginia\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1KVohKVpLK8"
      },
      "source": [
        "datos=pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "datos['tipos']=pd.Series(iris.target)\n",
        "datos.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mh_KMxuZgH0a"
      },
      "source": [
        "## Probar una división sobre la característica **sepal length (cm)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-GPO1CGgjgC"
      },
      "source": [
        "Ver como se distribuyen los valores de la característica"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AquRt7Rzp2vt"
      },
      "source": [
        "caracteristica=iris.feature_names[0] # Columna 0 'sepal lenght (cm)'\n",
        "datos[caracteristica].hist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pt-zI4Ehbfq"
      },
      "source": [
        "Utilizamos el valor 6 para realizar la partición\n",
        "\n",
        "- $Q_{izqierdo}=\\{x \\in datos| x[sepal\\ leng (cm)] \\le 6\\}$\n",
        "- $Q_{derecho}=\\{x \\in datos| x[sepal\\ leng (cm)] > 6\\}$\n",
        "\n",
        "Se utiliza la función [**cut**](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.cut.html) de la librería **pandas** que segmenta una serie en intervalos.\n",
        "\n",
        "En ejemplo se proponen dos intervalo :\n",
        "- Izquierdo (0,6]\n",
        "- Derecho (6,8]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kv5jMKtTsd_Z"
      },
      "source": [
        "from pandas._libs.interval import Interval #Construyo intervalos\n",
        "corte=6\n",
        "dv=pd.cut(datos[caracteristica],[0,corte,8]) #Doy los cortes que quiero tener. \n",
        "dv_izquierdo=datos[dv==Interval(0, corte, closed='right')] #Puedo cerrarlo o no para que el extremo se incluya o no. \n",
        "dv_derecho=datos[dv==Interval(corte, 8, closed='right')]\n",
        "len(dv_izquierdo),len(dv_derecho),len(datos)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMMYfN-CncTb"
      },
      "source": [
        "Valoramos los nodos obtenido **dv_izquierdo** y **dv_derecho**.\n",
        "- Obtenemos la probabilidad de cada clase $p_{m,k}$ haciendo uso de [**groupby**](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html?highlight=groupby#pandas.DataFrame.groupby) y **count** de **pandas**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EVJaYUat4ln"
      },
      "source": [
        "#Grupo izquierda. \n",
        "Nodo=dv_izquierdo\n",
        "sdv=Nodo.groupby('tipos',as_index=False).count()\n",
        "nizq=len(Nodo)\n",
        "sdv['Prob']=sdv[caracteristica]/nizq\n",
        "lpizq=sdv['Prob'].values\n",
        "sdv\n",
        "#Calculamos las probabilidades. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VT7OvgLOo0_7"
      },
      "source": [
        "#Grupo de la derecha. \n",
        "Nodo=dv_derecho\n",
        "sdv=Nodo.groupby('tipos',as_index=False).count()\n",
        "nder=len(Nodo)\n",
        "sdv['Prob']=sdv[caracteristica]/nder\n",
        "lpder=sdv['Prob'].values\n",
        "sdv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qx6LFfNbpa7b"
      },
      "source": [
        "Valoramos la partición:\n",
        "- Calculamos el valor de disparidad en cada nodo: Gini, Entropía y mal clasificación."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spiTMkjNp03x"
      },
      "source": [
        "def Gini (l_probabilidades):\n",
        "  s=0.0\n",
        "  for p in l_probabilidades:\n",
        "    s = s + p*(1-p)\n",
        "  return s\n",
        "\n",
        "def Entropia(l_probabilidades):\n",
        "  s = 0.0\n",
        "  log_list= np.log(l_probabilidades)\n",
        "  for (p,plog) in zip(l_probabilidades,log_list):\n",
        "    s= s +p *plog\n",
        "  return - s\n",
        "\n",
        "def MClasificacion(l_probabilidades):\n",
        "  return 1-max(l_probabilidades)\n",
        "\n",
        "  # in zip -> de dos o tres listas te genera una lista donde cada uno de los elementos de la lista es una tupla. Es decir: [1,2][a,b]->[1,a][2,b].\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSDEfP9xtrt8"
      },
      "source": [
        "Valoración utilizando el criterio **gini**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KU_m9PLHruZp"
      },
      "source": [
        "print(f'Gini(lpizq)={Gini(lpizq)}\\nGini(lpder)={Gini(lpder)}\\nG(izq,(sepal,6))={(nizq/(nizq+nder))*Gini(lpizq)+(nder/(nizq+nder))*Gini(lpder)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlcBDMc8tzV7"
      },
      "source": [
        "Valoración utilizando la **entropía**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnbFourFuAV3"
      },
      "source": [
        "print(f'Entropia(lpizq)={Entropia(lpizq)}\\nEntropia(lpder)={Entropia(lpder)}\\nG(izq,(sepal,6))={(nizq/(nizq+nder))*Entropia(lpizq)+(nder/(nizq+nder))*Entropia(lpder)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pqj6dIGHujWT"
      },
      "source": [
        "Valoración utilizando la **mal clasificación**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bpOMNhAus7L"
      },
      "source": [
        "print(f'Entropia(lpizq)={MClasificacion(lpizq)}\\nEntropia(lpder)={MClasificacion(lpder)}\\nG(izq,(sepal,6))={(nizq/(nizq+nder))*MClasificacion(lpizq)+(nder/(nizq+nder))*MClasificacion(lpder)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5YqRCzrwtTk"
      },
      "source": [
        "# Scikit-Learn [Árboles de decisión](https://scikit-learn.org/stable/modules/tree.html).\n",
        "\n",
        "**Árboles de clasificación** \\( [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier)\\).\n",
        "\n",
        "\n",
        "- **Leemos** los datos.\n",
        "- **Importamos** toda la funcionalidad de los árboles \\(**tree**\\).\n",
        "- **Creamos** el árbol de decisión para clasificar.\n",
        "- Lo instanciamos \\(**aprendemos**\\) con los datos **X** y sus clase **y**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiVgZgJvxXuz"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn import tree\n",
        "X, y = load_iris(return_X_y=True)\n",
        "clf = tree.DecisionTreeClassifier()\n",
        "clf = clf.fit(X, y) #Línea de ajuste. Como estamos en un ajuste supervisado necesito la x y la y para hacer el ajuste. Antes sólo la x y las clases no (y). "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpFRekqP28wA"
      },
      "source": [
        "Mostramos el árbol obtenido."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YW5jpGwFyU6r"
      },
      "source": [
        "tree.plot_tree(clf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-cAE6At88cj"
      },
      "source": [
        "Predecimos como con cualquier modelo ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xm5V6QxY9Gfb"
      },
      "source": [
        "clf.predict(X)!=y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si hay algo distinto o algo raro me daría algún True. "
      ],
      "metadata": {
        "id": "1EjgJ5UJxhzz"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8YrIQw63-iE"
      },
      "source": [
        "Podemos exporta el gráfico del árbol aun fichero **pdf** con el uso de la librería [**graphviz**](https://pypi.org/project/graphviz/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbgWkRWT0sY6"
      },
      "source": [
        "import graphviz \n",
        "dot_data = tree.export_graphviz(clf, out_file=None) \n",
        "graph = graphviz.Source(dot_data) \n",
        "graph.render(\"iris\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuDoPfuV4iV1"
      },
      "source": [
        "La exportación puede ser más *sofisticada* y a distintos *formatos*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nesxEUls1PFr"
      },
      "source": [
        "dot_data = tree.export_graphviz(clf, out_file=None, \n",
        "                     feature_names=iris.feature_names,  \n",
        "                     class_names=iris.target_names,  \n",
        "                     filled=True, rounded=True,  \n",
        "                     special_characters=True)  \n",
        "graph = graphviz.Source(dot_data)\n",
        "graph"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pezjTpCX71iz"
      },
      "source": [
        "La anchura del pétalo es menos importante que la longitud... y así vamos viendo los resultados. Los colores indican la complejidad, el más complejo es el blanco que es la combinación de todos. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1Z1Z3Gp1f7j"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.tree import export_text\n",
        "iris = load_iris()\n",
        "decision_tree = DecisionTreeClassifier(random_state=0, max_depth=2)\n",
        "decision_tree = decision_tree.fit(iris.data, iris.target)\n",
        "r = export_text(decision_tree, feature_names=iris['feature_names'])\n",
        "print(r)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9ovLSJI93Iz"
      },
      "source": [
        "# [**Orange**](https://orange.biolab.si/) un entorno integrado **Open Source**\n",
        "Como hacernos la vida un poco más fácil."
      ]
    }
  ]
}